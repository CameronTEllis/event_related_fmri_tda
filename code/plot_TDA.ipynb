{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for generating plots \n",
    "This notebook contains the tools for displaying the output of the event-related fMRI data analyses found at: https://github.com/CameronTEllis/event_related_fmri_tda. \n",
    "\n",
    "This assumes 1) you ran at least some of the simulation/analyses of the data (using \"./code/supervisor_supersubject.sh\" for instance). 2) you are able to launch the jupyter notebook with the same environment that you used to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import nibabel as nb\n",
    "import scipy.spatial.distance as sp_distance\n",
    "import sklearn.manifold as manifold\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import t\n",
    "import generate_graph_structure as graphs\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some functions that will be used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_node_brain_dist(filename, mask_vec):\n",
    "    nii = nb.load(filename)\n",
    "    data_vol = nii.get_data()\n",
    "\n",
    "    # Turn the data into a vector\n",
    "    data_vec = data_vol.reshape((np.prod(data_vol.shape[0:3])), data_vol.shape[3])\n",
    "\n",
    "    # Mask the data\n",
    "    data_masked = data_vec[mask_vec]\n",
    "\n",
    "    # Average the voxels in the masked region\n",
    "    data_av = np.mean(data_masked, 0)\n",
    "\n",
    "    # Reshape the data to be node by node\n",
    "    nodes = int(np.ceil(np.sqrt(len(data_av) * 2)))\n",
    "\n",
    "    # What are the indices for the upper triangle\n",
    "    idxs_u = np.triu_indices(nodes, 1)\n",
    "    idxs_l = np.tril_indices(nodes, -1)\n",
    "\n",
    "    # Insert the data into a dist matrix\n",
    "    data_dist = np.zeros((nodes, nodes))\n",
    "\n",
    "    # Add the data\n",
    "    data_dist[idxs_u[0], idxs_u[1]] = data_av\n",
    "\n",
    "    # Symmetrize the data\n",
    "    data_dist = (data_dist.T + data_dist) / 2\n",
    "    \n",
    "    # Return the distance matrix\n",
    "    return data_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_summary_stats(data, keys, line_style, color):\n",
    "    \n",
    "    plotting_data = []\n",
    "    plotting_error = []\n",
    "    for key in keys:\n",
    "        \n",
    "        # Pull out the data\n",
    "        data_point = data[key]\n",
    "        \n",
    "        # Is this a dictionary\n",
    "        if isinstance(data_point, dict):\n",
    "            # If these are different participants then average them and add error bars\n",
    "            ppt_data = list(data_point.values())\n",
    "            plotting_data += [np.mean(ppt_data)]\n",
    "            plotting_error += [np.std(ppt_data) / np.sqrt(len(ppt_data))]\n",
    "        else:\n",
    "            plotting_data += [data_point]\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.plot(plotting_data, line_style, color= color)\n",
    "    if len(plotting_error) == len(plotting_data):\n",
    "        plt.errorbar(np.arange(len(keys)), plotting_data, plotting_error, linestyle=line_style, ecolor=color, color=color)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "short_style = '--'\n",
    "long_style = '-'\n",
    "low_nodes_color = np.asarray([253, 231, 36]) / 255\n",
    "mid_nodes_color = np.asarray([102, 45, 145]) / 255\n",
    "high_nodes_color = np.asarray([255, 127, 14]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_name='../simulator_parameters/real_results/significant_mask.nii.gz'\n",
    "subject_root = '../simulated_data/node_brain_dist/'\n",
    "supersubject_root = '../simulated_data/supersubject_node_brain_dist/'\n",
    "nii = nb.load(mask_name)\n",
    "mask_vol = nii.get_data()\n",
    "mask_vec = mask_vol.reshape((np.prod(mask_vol.shape[0:3]))) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out the MDS representations from the fully simulated data\n",
    "This gives you a simple and easy way to visual the structure of the data in the signal voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resample_counter = 1\n",
    "deconvolution = 1\n",
    "subj = 1 # If zero then do the supersubject\n",
    "\n",
    "for nodes in [12, 15, 18]:\n",
    "    for repetitions_per_run in [5, 10]:\n",
    "\n",
    "        plt.figure(figsize=(12, 2))\n",
    "        signal_steps = [0.0, 0.25, 0.5, 0.75, 1.0, 5.0]\n",
    "        for counter, signal_size in enumerate(signal_steps):\n",
    "\n",
    "            # Set the subject name\n",
    "            if subj == 0:\n",
    "                subject_name = ''\n",
    "                file_root = supersubject_root\n",
    "            else:\n",
    "                subject_name = 'sub-%d_' % subj\n",
    "                file_root = subject_root\n",
    "\n",
    "            # Create a variable with a specific dp precision\n",
    "            signal_number = '%0.2f' % signal_size\n",
    "            if signal_number[-1] == '0':\n",
    "                signal_number = signal_number[:-1]\n",
    "\n",
    "            filename = '%s/%selipse_s-%s_1_1_t_5.0_1_1.0_%d_%d_%d_resample-%d.nii.gz' % (file_root, subject_name, signal_number, repetitions_per_run, nodes, deconvolution, resample_counter)\n",
    "\n",
    "            duration = (repetitions_per_run * nodes * 5 * 9) / 60  # How long in minutes is this experiment\n",
    "            plt.suptitle('reps-%d, nodes-%d, length-%0.1f, deconv-%d' % (repetitions_per_run, nodes, duration, deconvolution))\n",
    "            plt.subplot(1, len(signal_steps), counter + 1)\n",
    "            plt.xlabel('s-%0.1f' % signal_size)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            if os.path.exists(filename):\n",
    "                data_dist=average_node_brain_dist(filename, mask_vec)\n",
    "                graphs.make_mds(data_dist,\n",
    "                                dim=2,\n",
    "                                )\n",
    "        plt.savefig('../plots/example_mds_%snodes_%d_repetitions_%d.eps' % (subject_name, nodes, repetitions_per_run))\n",
    "        plt.savefig('../plots/example_mds_%snodes_%d_repetitions_%d.png' % (subject_name, nodes, repetitions_per_run))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resample_counter = 1\n",
    "deconvolution = 1\n",
    "subj = 0 # If zero then do the supersubject\n",
    "\n",
    "for nodes in [12, 15, 18]:\n",
    "    for repetitions_per_run in [5, 10]:\n",
    "\n",
    "        plt.figure(figsize=(12, 2))\n",
    "        signal_steps = [0.0, 0.25, 0.5, 0.75, 1.0, 5.0]\n",
    "        for counter, signal_size in enumerate(signal_steps):\n",
    "\n",
    "            # Set the subject name\n",
    "            if subj == 0:\n",
    "                subject_name = ''\n",
    "                file_root = supersubject_root\n",
    "            else:\n",
    "                subject_name = 'sub-%d_' % subj\n",
    "                file_root = subject_root\n",
    "\n",
    "            # Create a variable with a specific dp precision\n",
    "            signal_number = '%0.2f' % signal_size\n",
    "            if signal_number[-1] == '0':\n",
    "                signal_number = signal_number[:-1]\n",
    "\n",
    "            filename = '%s/%selipse_s-%s_1_1_t_5.0_1_1.0_%d_%d_%d_resample-%d.nii.gz' % (file_root, subject_name, signal_number, repetitions_per_run, nodes, deconvolution, resample_counter)\n",
    "\n",
    "            duration = (repetitions_per_run * nodes * 5 * 9) / 60  # How long in minutes is this experiment\n",
    "            plt.suptitle('reps-%d, nodes-%d, length-%0.1f, deconv-%d' % (repetitions_per_run, nodes, duration, deconvolution))\n",
    "            plt.subplot(1, len(signal_steps), counter + 1)\n",
    "            plt.xlabel('s-%0.1f' % signal_size)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            if os.path.exists(filename):\n",
    "                data_dist=average_node_brain_dist(filename, mask_vec)\n",
    "                graphs.make_mds(data_dist,\n",
    "                                dim=2,\n",
    "                                )\n",
    "        plt.savefig('../plots/example_mds_%snodes_%d_repetitions_%d.eps' % (subject_name, nodes, repetitions_per_run))\n",
    "        plt.savefig('../plots/example_mds_%snodes_%d_repetitions_%d.png' % (subject_name, nodes, repetitions_per_run))            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the stress and higher dimensionality of example MDS data\n",
    "Use this to observe how much variance the MDS plots described above show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stress = []\n",
    "\n",
    "signal_number = '5.0'\n",
    "mask_vec_roi = np.zeros(mask_vec.shape)\n",
    "mask_vec_roi[np.where(mask_vec == 1)[:27]] = 1\n",
    "mask_vec_roi = mask_vec_roi == 1\n",
    "filename = '%s/%selipse_s-%s_1_1_t_5.0_1_1.0_%d_%d_%d_resample-%d.nii.gz' % (file_root, subject_name, signal_number, repetitions_per_run, nodes, deconvolution, resample_counter)\n",
    "data_dist=average_node_brain_dist(filename, mask_vec_roi)\n",
    "\n",
    "for n_component in range(1, 10):\n",
    "    mds = manifold.MDS(n_components=n_component, dissimilarity='precomputed')\n",
    "    dist_obj = mds.fit(data_dist)\n",
    "    stress += [dist_obj.stress_]\n",
    "    \n",
    "plt.figure()\n",
    "plt.title('Stress of data')\n",
    "plt.plot(range(1, 10), stress)\n",
    "plt.ylabel('Stress')\n",
    "plt.xlabel('Components')\n",
    "\n",
    "# Look at the data in 4d\n",
    "plt.figure()\n",
    "graphs.make_mds(data_dist,\n",
    "                dim=4,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mds = manifold.MDS(n_components=4, dissimilarity='precomputed')  # Fit the\n",
    "# mds\n",
    "# object\n",
    "coords = mds.fit(data_dist).embedding_  # Find the mds coordinates\n",
    "\n",
    "np.save('%s/example_s-%s_dist.npy' % (file_root, signal_number), data_dist)\n",
    "np.save('%s/example_s-%s_coords.npy' % (file_root, signal_number), coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make max loop signal plots\n",
    "Make the plot of the maximum loop persistence for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all of the summary statistics \n",
    "fid = open('../searchlight_summary/signal_vs_flipped.txt', 'r')\n",
    "file_txt = fid.readlines()\n",
    "fid.close()\n",
    "\n",
    "subject_data = {}\n",
    "supersubject_data = {}\n",
    "for line in file_txt:\n",
    "    \n",
    "    # What condition is it\n",
    "    condition = line[line.find('elipse'):line.find('_loop')]\n",
    "    \n",
    "    # What is the value\n",
    "    val = float(line[line.find(': ') + 2:line.find('\\n')])\n",
    "    \n",
    "    # Is it a supersubject or not?\n",
    "    if line.find('sub-') > -1:\n",
    "        \n",
    "        ppt = line[line.find('sub-'):line.find('_elipse')]\n",
    "        \n",
    "        # Add a dictionary if it doesn't exist\n",
    "        if condition not in subject_data:\n",
    "            subject_data[condition] = {}\n",
    "            \n",
    "        # Add to the list    \n",
    "        subject_data[condition][ppt] = val\n",
    "    else:\n",
    "        supersubject_data[condition] = val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the variables\n",
    "signal_steps = ['0.0', '0.25', '0.5', '0.75', '1.0', '5.0']\n",
    "trials = 25\n",
    "nodes = 12\n",
    "resample = 1\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, short_style, high_nodes_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the variables\n",
    "signal_steps = ['0.0', '0.25', '0.5', '0.75', '1.0', '5.0']\n",
    "trials = 5\n",
    "nodes = 12\n",
    "resample = 1\n",
    "threshold = stats.t.ppf(0.9995, 441)\n",
    "\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, short_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, short_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, short_style, high_nodes_color)\n",
    "\n",
    "\n",
    "# Set the variables\n",
    "nodes = 12\n",
    "trials = 10\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, long_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, long_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_data, keys, long_style, high_nodes_color)\n",
    "\n",
    "plt.plot([0, len(signal_steps) - 1], [threshold, threshold], 'k--')\n",
    "plt.xticks(np.arange(len(signal_steps)), signal_steps)\n",
    "plt.ylabel('t stat')\n",
    "plt.xlabel('Percent signal change')\n",
    "plt.ylim([-10, 50])\n",
    "\n",
    "plt.savefig('../plots/subjectwise_max_loop_tstat.eps')\n",
    "plt.savefig('../plots/subjectwise_max_loop_tstat.png')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the variables\n",
    "signal_steps = ['0.0', '0.25', '0.5', '0.75', '1.0', '5.0']\n",
    "trials = 5\n",
    "nodes = 12\n",
    "resample = 1\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, short_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, short_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, short_style, high_nodes_color)\n",
    "\n",
    "\n",
    "# Set the variables\n",
    "nodes = 12\n",
    "trials = 10\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, long_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, long_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_data, keys, long_style, high_nodes_color)\n",
    "\n",
    "plt.plot([0, len(signal_steps) - 1], [threshold, threshold], 'k--')\n",
    "plt.xticks(np.arange(len(signal_steps)), signal_steps)\n",
    "plt.ylabel('t stat')\n",
    "plt.xlabel('Percent signal change')\n",
    "plt.ylim([-10, 50])\n",
    "\n",
    "plt.savefig('../plots/supersubject_max_loop_tstat.eps')\n",
    "plt.savefig('../plots/supersubject_max_loop_tstat.png')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the plots for the matching loop number\n",
    "Make the plots showing the frequency of getting exactly one loop (a single point in the 1-Dimensional persistence diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all of the summary statistics \n",
    "fid = open('../searchlight_summary/signal_ratio.txt', 'r')\n",
    "file_txt = fid.readlines()\n",
    "fid.close()\n",
    "\n",
    "subject_signal = {}\n",
    "supersubject_signal = {}\n",
    "for line in file_txt:\n",
    "    \n",
    "    # What condition is it\n",
    "    condition = line[line.find('elipse'):line.find('_loop')]\n",
    "    \n",
    "    # What is the value\n",
    "    val = float(line[line.find(': ') + 2:line.find('\\n')])\n",
    "    \n",
    "    # Is it a supersubject or not?\n",
    "    if line.find('sub-') > -1:\n",
    "        \n",
    "        ppt = line[line.find('sub-'):line.find('_elipse')]\n",
    "        \n",
    "        # Add a dictionary if it doesn't exist\n",
    "        if condition not in subject_signal:\n",
    "            subject_signal[condition] = {}\n",
    "            \n",
    "        # Add to the list    \n",
    "        subject_signal[condition][ppt] = val\n",
    "    else:\n",
    "        supersubject_signal[condition] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all of the summary statistics \n",
    "fid = open('../searchlight_summary/flipped_ratio.txt', 'r')\n",
    "file_txt = fid.readlines()\n",
    "fid.close()\n",
    "\n",
    "subject_noise = {}\n",
    "supersubject_noise = {}\n",
    "for line in file_txt:\n",
    "    \n",
    "    # What condition is it\n",
    "    condition = line[line.find('elipse'):line.find('_loop')]\n",
    "    \n",
    "    if condition.find('_12_') > 0:\n",
    "        condition_name = 'low'\n",
    "    elif condition.find('_15_') > 0:\n",
    "        condition_name = 'mid'\n",
    "    elif condition.find('_18_') > 0:\n",
    "        condition_name = 'high'\n",
    "        \n",
    "    # What is the value\n",
    "    val = float(line[line.find(': ') + 2:line.find('\\n')])\n",
    "    \n",
    "    # Is it a supersubject or not?\n",
    "    if line.find('sub-') > -1:\n",
    "        # Add a dictionary if it doesn't exist\n",
    "        if condition_name not in subject_noise:\n",
    "            subject_noise[condition_name] = []\n",
    "            \n",
    "        subject_noise[condition_name] += [val]\n",
    "    else:\n",
    "        # Add a dictionary if it doesn't exist\n",
    "        if condition_name not in supersubject_noise:\n",
    "            supersubject_noise[condition_name] = []\n",
    "            \n",
    "        supersubject_noise[condition_name] += [val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the variables\n",
    "signal_steps = ['0.0', '0.25', '0.5', '0.75', '1.0', '5.0']\n",
    "trials = 5\n",
    "nodes = 12\n",
    "resample = 1\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, short_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, short_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, short_style, high_nodes_color)\n",
    "\n",
    "\n",
    "# Set the variables\n",
    "nodes = 12\n",
    "trials = 10\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, long_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, long_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(subject_signal, keys, long_style, high_nodes_color)\n",
    "\n",
    "# Plot the noise pattern\n",
    "plt.axhspan(np.min(subject_noise['low']), np.max(subject_noise['low']), xmin=0.91,xmax=0.94, alpha=0.1, color=low_nodes_color)\n",
    "plt.axhspan(np.min(subject_noise['mid']), np.max(subject_noise['mid']), xmin=0.941, xmax=0.97, alpha=0.1, color=mid_nodes_color)\n",
    "plt.axhspan(np.min(subject_noise['high']), np.max(subject_noise['high']), xmin=0.971, xmax=1.0, alpha=0.1, color=high_nodes_color)\n",
    "\n",
    "# Plot the graph features\n",
    "plt.xticks(np.arange(len(signal_steps)), signal_steps)\n",
    "plt.ylabel('t stat')\n",
    "plt.xlabel('Percent signal change')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 5.5])\n",
    "\n",
    "plt.savefig('../plots/subjectwise_ratio_tstat.eps')\n",
    "plt.savefig('../plots/subjectwise_ratio_tstat.png')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the variables\n",
    "signal_steps = ['0.0', '0.25', '0.5', '0.75', '1.0', '5.0']\n",
    "trials = 5\n",
    "nodes = 12\n",
    "resample = 1\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, short_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, short_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, short_style, high_nodes_color)\n",
    "\n",
    "\n",
    "# Set the variables\n",
    "nodes = 12\n",
    "trials = 10\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, long_style, low_nodes_color)\n",
    "\n",
    "nodes = 15\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, long_style, mid_nodes_color)\n",
    "\n",
    "nodes = 18\n",
    "\n",
    "keys = []\n",
    "for s in signal_steps:\n",
    "\n",
    "    # Store the keys\n",
    "    keys += ['elipse_s-%s_1_1_t_5.0_1_1.0_%s_%d_1_resample-%d' % (s, trials, nodes, resample)]\n",
    "    \n",
    "plot_summary_stats(supersubject_signal, keys, long_style, high_nodes_color)\n",
    "\n",
    "# Plot the noise pattern\n",
    "plt.axhspan(np.min(supersubject_noise['low']), np.max(supersubject_noise['low']), xmin=0.91,xmax=0.94, alpha=0.1, color=low_nodes_color)\n",
    "plt.axhspan(np.min(supersubject_noise['mid']), np.max(supersubject_noise['mid']), xmin=0.941, xmax=0.97, alpha=0.1, color=mid_nodes_color)\n",
    "plt.axhspan(np.min(supersubject_noise['high']), np.max(supersubject_noise['high']), xmin=0.971, xmax=1.0, alpha=0.1, color=high_nodes_color)\n",
    "\n",
    "# Plot the graph features\n",
    "plt.xticks(np.arange(len(signal_steps)), signal_steps)\n",
    "plt.ylabel('t stat')\n",
    "plt.xlabel('Percent signal change')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 5.5])\n",
    "\n",
    "plt.savefig('../plots/supersubject_ratio_tstat.eps')\n",
    "plt.savefig('../plots/supersubject_ratio_tstat.png')            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the elements for the methods figure in the manuscript\n",
    "This figure shows the topological structure being inserted in to the brain, the ROI containing signal, an example distance matrix and an example persistence diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords=graphs.elipse(nodes=12, x_coef=1, y_coef=1)\n",
    "dist=graphs.coord2dist(coords)\n",
    "plt.figure()\n",
    "graphs.make_mds(dist,\n",
    "                dim=2,\n",
    "                )\n",
    "plt.axis('off');\n",
    "plt.savefig('../plots/example_loop.eps')\n",
    "plt.savefig('../plots/example_loop.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a brain slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../simulated_data/nifti/sub-1_r1_elipse_s-5.0_1_1_t_5.0_1_1.0_5_12_1.nii.gz'\n",
    "\n",
    "nii = nb.load(filename)\n",
    "vol = nii.get_data()\n",
    "\n",
    "# Pull out the slices to show\n",
    "x_idx = 11\n",
    "brain_slice = np.rot90(vol[x_idx, :, :, 0], 1)\n",
    "mask_slice = np.rot90(mask_vol[x_idx, :, :], 1)\n",
    "\n",
    "# Find an example searchlight\n",
    "y_idx = np.where(mask_slice == 1)[0][10]\n",
    "z_idx = np.where(mask_slice == 1)[1][10]\n",
    "\n",
    "# Create a searchlight mask\n",
    "searchlight_slice = np.zeros(mask_slice.shape)\n",
    "searchlight_slice[y_idx - 1:y_idx + 2, z_idx - 1:z_idx + 2] = 1\n",
    "\n",
    "# Set the range to 1\n",
    "brain_slice /= brain_slice.max()\n",
    "mask_slice /= mask_slice.max()\n",
    "\n",
    "# Construct RGB version of grey-level image\n",
    "img_rgb = np.dstack((brain_slice, brain_slice, brain_slice))\n",
    "\n",
    "mask_rgb = np.zeros(img_rgb.shape)\n",
    "mask_rgb[:, :, 2] = mask_slice\n",
    "\n",
    "searchlight_rgb = np.zeros(img_rgb.shape)\n",
    "searchlight_rgb[:, :, 1] = searchlight_slice\n",
    "\n",
    "# Convert the input image and color mask to Hue Saturation Value (HSV)\n",
    "# colorspace\n",
    "img_hsv = colors.rgb_to_hsv(img_rgb)\n",
    "mask_hsv = colors.rgb_to_hsv(mask_rgb)\n",
    "searchlight_hsv = colors.rgb_to_hsv(searchlight_rgb)\n",
    "\n",
    "# Replace the hue and saturation of the original image\n",
    "# with that of the color mask\n",
    "alpha = 0.7\n",
    "img_hsv[:, :, 0] = mask_hsv[:, :, 0]\n",
    "img_hsv[:, :, 1] = mask_hsv[:, :, 1] * alpha\n",
    "\n",
    "# Super impose the searchlight\n",
    "roi_hue = np.unique(searchlight_hsv[:, :, 0])[1]\n",
    "roi_sat = np.unique(searchlight_hsv[:, :, 1])[1]\n",
    "idxs = np.where(searchlight_hsv[:, :, 0] == roi_hue)\n",
    "\n",
    "img_hsv[idxs[0], idxs[1], 0] = roi_hue\n",
    "img_hsv[idxs[0], idxs[1], 1] = roi_sat\n",
    "\n",
    "# Convert back into rgb\n",
    "img_masked = colors.hsv_to_rgb(img_hsv)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_masked)\n",
    "plt.axis('off')\n",
    "\n",
    "# Example brain\n",
    "plt.savefig('../plots/example_brain_searchlight.eps')\n",
    "plt.savefig('../plots/example_brain_searchlight.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the distrance matrix to be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../simulated_data/node_brain_dist//sub-1_elipse_s-1.0_1_1_t_5.0_1_1.0_10_12_1_resample-1.nii.gz'\n",
    "\n",
    "data_dist = average_node_brain_dist(filename, mask_vec)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(data_dist)\n",
    "plt.axis('off')\n",
    "plt.savefig('../plots/example_distance_mat.eps')\n",
    "plt.savefig('../plots/example_distance_mat.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run persistent homology on a searchlight voxel\n",
    "If TDA has trouble being loaded in to notebooks, use the script as specified below to run persistent homology outside of the notebook and then load in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an example barcode\n",
    "input_file = 'simulated_data/node_brain_dist//sub-1_elipse_s-1.0_1_1_t_5.0_1_1.0_10_12_1_resample-1.nii.gz'\n",
    "output_file = 'searchlight_summary/example_barcode.npy' # Use path relative to the base\n",
    "coordinates = '[%d,%d,%d]' % (x_idx,y_idx,z_idx)\n",
    "!cd ../; ./code/run_TDA_coordinate.sh $input_file $coordinates $output_mat; cd code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the barcode\n",
    "barcode = np.load('../' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the persistence diagram\n",
    "plt.figure()\n",
    "\n",
    "# Pull out all the features\n",
    "births = barcode[:, 0]\n",
    "deaths = barcode[:, 1]\n",
    "betti = barcode[:, 2]\n",
    "\n",
    "plt.scatter(births[betti==1], deaths[betti==1], marker='x')\n",
    "plt.scatter(births[betti==0], deaths[betti==0])\n",
    "\n",
    "# Get the diagonal\n",
    "all_vals = barcode[:,:2].flatten()\n",
    "min_val = all_vals.min()\n",
    "max_val = all_vals[np.argsort(all_vals)[-2]]  # So as not to get an inf\n",
    "\n",
    "plt.plot([min_val, max_val], [min_val, max_val], c='k')\n",
    "\n",
    "# Hide units\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.xlabel('Birth')\n",
    "plt.ylabel('Death')\n",
    "\n",
    "plt.savefig('../plots/example_persistence_diagram.png')\n",
    "plt.savefig('../plots/example_persistence_diagram.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot examples of the distance matrix and the persistent homology\n",
    "To further query your data you can plot distance matrices, persistence diagrams and MDS plots from specific regions in the simulated brains in order to explore the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec2mat(vec):\n",
    "# Convert the distance vector into a matrix\n",
    "    nodes = int(np.ceil(np.sqrt(len(vec) * 2)))  # Unravel the data\n",
    "    distance_matrix = np.zeros((nodes, nodes))\n",
    "    x, y = np.triu_indices(nodes, 1)\n",
    "    distance_matrix[x, y] = vec\n",
    "    return distance_matrix\n",
    "\n",
    "def persistent_graph(barcode):\n",
    "    # Pull out all the features\n",
    "    births = barcode[:, 0]\n",
    "    deaths = barcode[:, 1]\n",
    "    betti = barcode[:, 2]\n",
    "\n",
    "    plt.scatter(births[betti==1], deaths[betti==1], marker='x')\n",
    "    plt.scatter(births[betti==0], deaths[betti==0])\n",
    "\n",
    "    # Get the diagonal\n",
    "    all_vals = barcode[:,:2].flatten()\n",
    "    min_val = all_vals.min()\n",
    "    max_val = all_vals[np.argsort(all_vals)[-2]]  # So as not to get an inf\n",
    "\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], c='k')\n",
    "\n",
    "    # Hide units\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.xlabel('Birth')\n",
    "    plt.ylabel('Death')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scratch space\n",
    "xcoord = 6\n",
    "ycoord = 34\n",
    "zcoord = 16\n",
    "repetitions = 5\n",
    "nodes = 12\n",
    "sig = '5.0'\n",
    "\n",
    "aggregate = np.zeros((20, (nodes ** 2) // 2 - (nodes // 2)))\n",
    "for ppt in range(1, 21):\n",
    "    file = '../simulated_data/node_brain_dist/sub-%d_elipse_s-%s_1_1_t_5.0_1_1.0_%d_%d_1_resample-1.nii.gz' % (ppt, sig, repetitions, nodes)\n",
    "    \n",
    "    data = nb.load(file).get_data()\n",
    "    \n",
    "    aggregate[ppt - 1, :] = data[xcoord, ycoord, zcoord, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the code for computing persistent homology on a single set of voxels\n",
    "#!cd ..; for ppt_counter in `seq 1 20`; do echo ./code/run_TDA_coordinate.sh simulated_data/node_brain_dist/sub-${ppt_counter}\\_elipse_s-${sig}\\_1_1_t_5.0_1_1.0_${repetitions}_${nodes}_1_resample-1.nii.gz [$xcoord,$ycoord,$zcoord] ppt_${ppt_counter}\\_${nodes}_${sig}.npy; done; cd code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = '../simulated_data/supersubject_node_brain_dist/elipse_s-%s_1_1_t_5.0_1_1.0_10_12_1_resample-1.nii.gz' % sig\n",
    "    \n",
    "average = nb.load(file).get_data()[xcoord, ycoord, zcoord, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the code for computing persistent homology on a single set of voxels\n",
    "#!cd ..; ./code/run_TDA_coordinate.sh simulated_data/supersubject_node_brain_dist/elipse_s-${sig}\\_1_1_t_5.0_1_1.0_10_12_1_resample-1.nii.gz [$xcoord,$ycoord,$zcoord] super_12_${sig}.npy; cd code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,80))\n",
    "total_ppts = 20\n",
    "for ppt in range(total_ppts):\n",
    "    \n",
    "    # Plot distance matrix\n",
    "    dist = vec2mat(aggregate[ppt, :]) + vec2mat(aggregate[ppt, :]).T\n",
    "    plt.subplot(total_ppts, 3, (ppt * 3) + 1)\n",
    "    plt.imshow(dist)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot persistent homology\n",
    "    barcode = np.load('../ppt_%d_%d_%s.npy' % (ppt + 1, nodes, sig))\n",
    "    plt.subplot(total_ppts, 3, (ppt * 3) + 2)\n",
    "    persistent_graph(barcode)\n",
    "    \n",
    "    # Plot mds\n",
    "    plt.subplot(total_ppts, 3, (ppt * 3) + 3)\n",
    "    graphs.make_mds(dist,\n",
    "                    dim=2,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot distance matrix\n",
    "dist = vec2mat(average) + vec2mat(average).T\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(dist)\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot persistent homology\n",
    "barcode = np.load('../super_%d_%s.npy' % (nodes, sig))\n",
    "plt.subplot(1, 3, 2)\n",
    "persistent_graph(barcode)\n",
    "\n",
    "# Plot mds\n",
    "plt.subplot(1, 3, 3)\n",
    "graphs.make_mds(dist,\n",
    "                dim=2,\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
